{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imdb-text-analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Denjj/imdb-text-analysis/blob/master/imdb_text_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0-pEU9zv9xj",
        "colab_type": "text"
      },
      "source": [
        "# Importing libraries and dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6K0VNLDv6-t",
        "colab_type": "code",
        "outputId": "6a687ce9-91c5-45d9-bc1a-5ced0f385cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "from keras.datasets import imdb\n",
        "import numpy as num\n",
        "\n",
        "# Import the imdb dataset into tensorflow\n",
        "(x_train, y_train),(x_test, y_test) = imdb.load_data()\n",
        "\n",
        "# Imdb dataset contains 25,000 movie reviews from IMDB\n",
        "# Data is preprocessed. Each review is encoded as a sequence of word indexes (integers)\n",
        "# Words are indexed by overall frequency in the dataset.\n",
        "# X axis contains the sequence of integers\n",
        "# Y axis contains the label of the review, Negative(0) or Positive(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o8k2rbTwB8Q",
        "colab_type": "text"
      },
      "source": [
        "# Observing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBYQnibbwC9v",
        "colab_type": "code",
        "outputId": "9119b638-e13b-426c-fbf5-dcbe5c4e8710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"Number of reviews in train data set is {}\".format(len(x_train)))\n",
        "print(\"Number of labels in train data set is {}\".format(len(y_train)))\n",
        "print(\"Number of reviews in test set is {}\".format(len(x_test)))\n",
        "print(\"Number of labels in test set is {}\".format(len(y_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews in train data set is 25000\n",
            "Number of labels in train data set is 25000\n",
            "Number of reviews in test set is 25000\n",
            "Number of labels in test set is 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0VthxScwF38",
        "colab_type": "code",
        "outputId": "9eb6ae02-e4d5-4095-e9a8-7cc5999364c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "for i in range(15):\n",
        "  print(\"Review #{} contains a sequence of length {}\".format(i+1, len(x_train[i])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review #1 contains a sequence of length 218\n",
            "Review #2 contains a sequence of length 189\n",
            "Review #3 contains a sequence of length 141\n",
            "Review #4 contains a sequence of length 550\n",
            "Review #5 contains a sequence of length 147\n",
            "Review #6 contains a sequence of length 43\n",
            "Review #7 contains a sequence of length 123\n",
            "Review #8 contains a sequence of length 562\n",
            "Review #9 contains a sequence of length 233\n",
            "Review #10 contains a sequence of length 130\n",
            "Review #11 contains a sequence of length 450\n",
            "Review #12 contains a sequence of length 99\n",
            "Review #13 contains a sequence of length 117\n",
            "Review #14 contains a sequence of length 238\n",
            "Review #15 contains a sequence of length 109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ4V8cUXwEcV",
        "colab_type": "text"
      },
      "source": [
        "Line 27 shows that each review contains a different amount of integers in the sequence.\n",
        "This make sense because not every movie review contains the same number of words.\n",
        "Because of this, the data needs to be standardized with the same length for each sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFQWeBNowIib",
        "colab_type": "text"
      },
      "source": [
        "# Preparing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qew8t9swIJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Truncate the review sequence length into 256 integers, for both training and test data\n",
        "# Sequences less than 256 integers in length will be padded with 0 values \n",
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, value=0, maxlen=256)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(x_test, value=0, maxlen=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRLLJdHiwNCS",
        "colab_type": "code",
        "outputId": "6791b840-3f11-489b-894c-e05e12fac8c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "for i in range(15):\n",
        "  print(\"Review #{} contains a sequence of length {}\".format(i+1, len(x_train[i])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review #1 contains a sequence of length 256\n",
            "Review #2 contains a sequence of length 256\n",
            "Review #3 contains a sequence of length 256\n",
            "Review #4 contains a sequence of length 256\n",
            "Review #5 contains a sequence of length 256\n",
            "Review #6 contains a sequence of length 256\n",
            "Review #7 contains a sequence of length 256\n",
            "Review #8 contains a sequence of length 256\n",
            "Review #9 contains a sequence of length 256\n",
            "Review #10 contains a sequence of length 256\n",
            "Review #11 contains a sequence of length 256\n",
            "Review #12 contains a sequence of length 256\n",
            "Review #13 contains a sequence of length 256\n",
            "Review #14 contains a sequence of length 256\n",
            "Review #15 contains a sequence of length 256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78MsHnTgwOpO",
        "colab_type": "text"
      },
      "source": [
        "# Creating the neural network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agCf4AkYwSVF",
        "colab_type": "code",
        "outputId": "8bebe2b3-1421-42b4-e6cd-c55bb9d9c774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(100000, 16)) # Input shape is 100,000 because anything lower errors during model fitting\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
        "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid)) # Sigmoid activation function is ideal for binary targets\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          1600000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,600,289\n",
            "Trainable params: 1,600,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwmz9qES_nqY",
        "colab_type": "text"
      },
      "source": [
        "# Training and deploying neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBbcAOVeuT5R",
        "colab_type": "code",
        "outputId": "ab788c2a-17cd-48d1-cacb-1288c431bdce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "# Train and deploy neural network\n",
        "# Model is compiled using binary crossentropy loss reduction since targets are in binary format\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 20s 805us/sample - loss: 0.5755 - acc: 0.7568 - val_loss: 0.4069 - val_acc: 0.8408\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 19s 757us/sample - loss: 0.3122 - acc: 0.8800 - val_loss: 0.2987 - val_acc: 0.8786\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 19s 761us/sample - loss: 0.2406 - acc: 0.9076 - val_loss: 0.2797 - val_acc: 0.8854\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 19s 768us/sample - loss: 0.2068 - acc: 0.9212 - val_loss: 0.2795 - val_acc: 0.8860\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 19s 766us/sample - loss: 0.1848 - acc: 0.9305 - val_loss: 0.3008 - val_acc: 0.8758\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 20s 785us/sample - loss: 0.1686 - acc: 0.9374 - val_loss: 0.2871 - val_acc: 0.8856\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 19s 762us/sample - loss: 0.1560 - acc: 0.9435 - val_loss: 0.2911 - val_acc: 0.8851\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 19s 749us/sample - loss: 0.1450 - acc: 0.9473 - val_loss: 0.2990 - val_acc: 0.8834\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 19s 759us/sample - loss: 0.1368 - acc: 0.9509 - val_loss: 0.3238 - val_acc: 0.8761\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 19s 762us/sample - loss: 0.1295 - acc: 0.9537 - val_loss: 0.3221 - val_acc: 0.8782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe83e373a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS_mjuAczOOF",
        "colab_type": "text"
      },
      "source": [
        "Training after 10 epochs resulted in an accuracy of 87.82%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96OWxzjGIMVR",
        "colab_type": "text"
      },
      "source": [
        "# Optional: Manipulating data for higher accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyKWacBpLHTh",
        "colab_type": "text"
      },
      "source": [
        "**Test 1: Pad sequence to 128 integers**  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9EqiiybISLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This time, the review sequence length is truncated into 128 integers\n",
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, value=0, maxlen=128)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(x_test, value=0, maxlen=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9ht_2bRIcFZ",
        "colab_type": "code",
        "outputId": "af463cdf-a3a2-4d8b-e9de-69bb5cec2455",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "for i in range(15):\n",
        "  print(\"Review #{} contains a sequence of length {}\".format(i+1, len(x_train[i])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review #1 contains a sequence of length 128\n",
            "Review #2 contains a sequence of length 128\n",
            "Review #3 contains a sequence of length 128\n",
            "Review #4 contains a sequence of length 128\n",
            "Review #5 contains a sequence of length 128\n",
            "Review #6 contains a sequence of length 128\n",
            "Review #7 contains a sequence of length 128\n",
            "Review #8 contains a sequence of length 128\n",
            "Review #9 contains a sequence of length 128\n",
            "Review #10 contains a sequence of length 128\n",
            "Review #11 contains a sequence of length 128\n",
            "Review #12 contains a sequence of length 128\n",
            "Review #13 contains a sequence of length 128\n",
            "Review #14 contains a sequence of length 128\n",
            "Review #15 contains a sequence of length 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5izxMFpMIfUN",
        "colab_type": "code",
        "outputId": "f638da33-225c-4639-a4dd-bb59fceb02e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "model2 = keras.Sequential()\n",
        "model2.add(keras.layers.Embedding(100000, 16))\n",
        "model2.add(keras.layers.GlobalAveragePooling1D())\n",
        "model2.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
        "model2.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
        "\n",
        "model2.summary()\n",
        "\n",
        "model2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model2.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 16)          1600000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,600,289\n",
            "Trainable params: 1,600,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 19s 751us/sample - loss: 0.5642 - acc: 0.7760 - val_loss: 0.3984 - val_acc: 0.8370\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 19s 742us/sample - loss: 0.3196 - acc: 0.8680 - val_loss: 0.3171 - val_acc: 0.8624\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 19s 741us/sample - loss: 0.2579 - acc: 0.8951 - val_loss: 0.3043 - val_acc: 0.8695\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 19s 745us/sample - loss: 0.2281 - acc: 0.9083 - val_loss: 0.3040 - val_acc: 0.8696\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 19s 747us/sample - loss: 0.2072 - acc: 0.9189 - val_loss: 0.3099 - val_acc: 0.8681\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 19s 769us/sample - loss: 0.1926 - acc: 0.9254 - val_loss: 0.3164 - val_acc: 0.8682\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 19s 767us/sample - loss: 0.1803 - acc: 0.9311 - val_loss: 0.3265 - val_acc: 0.8655\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 18s 734us/sample - loss: 0.1712 - acc: 0.9353 - val_loss: 0.3419 - val_acc: 0.8608\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 19s 744us/sample - loss: 0.1631 - acc: 0.9384 - val_loss: 0.3518 - val_acc: 0.8583\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 19s 749us/sample - loss: 0.1558 - acc: 0.9412 - val_loss: 0.3494 - val_acc: 0.8608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe83efc9518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWS4JGwHJ3L_",
        "colab_type": "text"
      },
      "source": [
        "Padding the review sequence length into 128 integers, down from 256 integers, resulted in an accuracy loss of .0168 with the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLprm-NkL6mZ",
        "colab_type": "text"
      },
      "source": [
        "**Test 2: Pad sequence to 256 Integers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McpyAhSfKeJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now, the review sequence length is truncated to 512 integers\n",
        "(x_train2, y_train2),(x_test2, y_test2) = imdb.load_data()\n",
        "x_train2 = keras.preprocessing.sequence.pad_sequences(x_train, value=0, maxlen=512)\n",
        "x_test2 = keras.preprocessing.sequence.pad_sequences(x_test, value=0, maxlen=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY5pucV3Ko93",
        "colab_type": "code",
        "outputId": "56c32ac6-4c3f-48a9-b393-c9874a724dde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "model3 = keras.Sequential()\n",
        "model3.add(keras.layers.Embedding(100000, 16))\n",
        "model3.add(keras.layers.GlobalAveragePooling1D())\n",
        "model3.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
        "model3.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
        "\n",
        "model3.summary()\n",
        "\n",
        "model3.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model3.fit(x_train2, y_train2, validation_data=(x_test2, y_test2), epochs=10, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 16)          1600000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,600,289\n",
            "Trainable params: 1,600,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 19s 759us/sample - loss: 0.6519 - acc: 0.6796 - val_loss: 0.5602 - val_acc: 0.7812\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 19s 770us/sample - loss: 0.4430 - acc: 0.8245 - val_loss: 0.3776 - val_acc: 0.8396\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 19s 751us/sample - loss: 0.3259 - acc: 0.8630 - val_loss: 0.3283 - val_acc: 0.8578\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 19s 749us/sample - loss: 0.2841 - acc: 0.8827 - val_loss: 0.3131 - val_acc: 0.8650\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 19s 754us/sample - loss: 0.2588 - acc: 0.8942 - val_loss: 0.3633 - val_acc: 0.8380\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 19s 753us/sample - loss: 0.2412 - acc: 0.9042 - val_loss: 0.3052 - val_acc: 0.8694\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 19s 743us/sample - loss: 0.2259 - acc: 0.9096 - val_loss: 0.3027 - val_acc: 0.8702\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 19s 745us/sample - loss: 0.2150 - acc: 0.9164 - val_loss: 0.3052 - val_acc: 0.8704\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 19s 757us/sample - loss: 0.2051 - acc: 0.9200 - val_loss: 0.3723 - val_acc: 0.8448\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 19s 749us/sample - loss: 0.1967 - acc: 0.9244 - val_loss: 0.3471 - val_acc: 0.8560\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe83c30a278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_ViIu5mLhwO",
        "colab_type": "text"
      },
      "source": [
        "Truncating the review sequence length into 512 integers resulted in an accuracy loss of .0449 with the test data, as compared to the original 256 sequence length."
      ]
    }
  ]
}